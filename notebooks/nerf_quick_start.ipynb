{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Quick Start Notebook\n",
    "\n",
    "Plank-ing Hyundong 3D Reconstruction Project\n",
    "Created 2022.07.05 <br>\n",
    "\n",
    "There are 4 Steps in this notebook.<br>\n",
    "1. Sampling images from video\n",
    "2. Get camera poses with COLMAP\n",
    "3. Run NeRF\n",
    "4. Get mesh file\n",
    "\n",
    "\n",
    "__You can skip step 1, 2 by revising the directory path at Step 3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "\n",
    "- PlankHyundong\n",
    "    - notebook\n",
    "        - __nerf_quick_start.ipynb__\n",
    "        - nerf_colab.ipynb\n",
    "        - nerf_wandb_colab.ipynb\n",
    "        - colmap_colab.ipynb\n",
    "    - utils\n",
    "    - data\n",
    "        - video\n",
    "            - video.mp4\n",
    "        - base_images\n",
    "            - images\n",
    "                - image1.jpg\n",
    "                - image2.jpg\n",
    "                - ...\n",
    "            - pose.npy\n",
    "        - custom_images\n",
    "            - images\n",
    "            \n",
    "\n",
    "> 'base_images' folder is for who want to skip step 1, 2\n",
    "<br><br>\n",
    "> 'custom_images' folder is for who want to execute from step 1.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Video Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Video file path\n",
    "data_path = '/PlankHyundong/data/video/video.mp4'\n",
    "save_path = '/PlankHyundong/data/custom_images'\n",
    "\n",
    "# Set the number of frame\n",
    "frame = 50\n",
    "\n",
    "vidcap = cv2.VideoCapture(dir)\n",
    "                \n",
    "cnt, num = 0, 1 # cnt -> Input frame #, num -> output Frame #.\n",
    "\n",
    "total_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cycle = int(total_length / frame) # calculate cycle\n",
    "\n",
    "while vidcap.isOpened():\n",
    "    ret,image = vidcap.read()\n",
    "    if num > frame:\n",
    "        break\n",
    "    if ret and cnt % cycle == 0:  \n",
    "        \n",
    "        try:\n",
    "            cv2.imwrite(f\"{save_path}/image{num}.jpg\", image)\n",
    "            num+=1\n",
    "        except:\n",
    "            print(\"fail\")\n",
    "            \n",
    "    cnt += 1\n",
    "    \n",
    "vidcap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "### Run COLMAP to get camera pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!sudo apt-get install \\\n",
    "    git \\\n",
    "    cmake \\\n",
    "    build-essential \\\n",
    "    libboost-program-options-dev \\\n",
    "    libboost-filesystem-dev \\\n",
    "    libboost-graph-dev \\\n",
    "    libboost-regex-dev \\\n",
    "    libboost-system-dev \\\n",
    "    libboost-test-dev \\\n",
    "    libeigen3-dev \\\n",
    "    libsuitesparse-dev \\\n",
    "    libfreeimage-dev \\\n",
    "    libgoogle-glog-dev \\\n",
    "    libgflags-dev \\\n",
    "    libglew-dev \\\n",
    "    qtbase5-dev \\\n",
    "    libqt5opengl5-dev \\\n",
    "    libcgal-dev \\\n",
    "    libcgal-qt5-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Ceres-solver\n",
    "\n",
    "- It takes 10 ~ 20 minutes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libatlas-base-dev libsuitesparse-dev\n",
    "!git clone https://ceres-solver.googlesource.com/ceres-solver\n",
    "%cd ceres-solver\n",
    "!git checkout $(git describe --tags) # Checkout the latest release\n",
    "%mkdir build\n",
    "%cd build\n",
    "!cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF\n",
    "!make\n",
    "!sudo make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install COLMAP\n",
    "- It takes 10 ~ 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libmetis-dev # https://github.com/colmap/colmap/issues/1469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in Google Colab & Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/Fyusion/LLFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/LLFF\n",
    "!python imgs2poses.py /content/PlankHyundong/data/custom_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "### Run NeRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We used tensorflow 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 1.x\n",
    "except ValueError:\n",
    "    # 만약 %tensorflow_version 1.x magic 명령어가 작동하지 않는 경우\n",
    "    !pip uninstall --yes tensorflow\n",
    "    !pip install tensorflow==1.15\n",
    "    import tensorflow\n",
    "    print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install dependent-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt -qq install imagemagick\n",
    "!pip install ConfigArgParse -qqq\n",
    "!pip install imageio-ffmpeg -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clone NeRF source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ProtossDragoon/nerf-wandb.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd nerf-wandb\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "dataset_name = 'hyundong360_100'\n",
    "downsample_factor = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n",
    "netdepth = 4 #@param {type:\"slider\", min:4, max:16, step:2}\n",
    "netwidth = 64 #@param {type:\"slider\", min:64, max:256, step:4}\n",
    "experiment_name = f'{dataset_name}_{downsample_factor}_downsampled_{now}'\n",
    "max_iter = 30000 #@param\n",
    "learning_rate = 0.01 #@param\n",
    "video_saving_cnt = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "n_samples = 128 #@param {type:\"slider\", min:32, max:256, step:32}\n",
    "\n",
    "# fine 모델에서 사용되는 샘플 개수는 coarse 모델의 sampling 개수의 2배로 설정한다.\n",
    "# 공식 논문에서 제안하는 대로, 64이면 128.\n",
    "n_importance = n_samples * 2\n",
    "\n",
    "# Reproduce 를 위해 고정 random_seed 를 사용\n",
    "random_seed = 777 #@param\n",
    "\n",
    "# tradeoff: memory <-> speed (training 에는 속도와 성능 모두에 영향을 미치지 않음. 학습 도중 동영상을 만들 때 OOM 이 난다면 충분히 낮출 것)\n",
    "rendering_speed = 2048 #@param {type:\"slider\", min:1024, max:16384, step:1024}\n",
    "\n",
    "# tradeoff: memory <-> result\n",
    "n_points_per_ray = 65536 #@param {type:\"slider\", min:2048, max:262144, step:1024}\n",
    "\n",
    "_dummy_dir = f'./logs/{experiment_name}'\n",
    "_tensorboard_logdir = f'./logs/summaries/{experiment_name}'\n",
    "print(f'experiment: {experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_nerf.py \\\n",
    "    --wandbproject {'plank-hyundong'} \\\n",
    "    --wandbentity {'plank-hyundong'} \\\n",
    "    --maxiter {max_iter} \\\n",
    "    --datadir /content/drive/MyDrive/dev/llff_data/{dataset_name} \\\n",
    "    --dataset_type llff \\\n",
    "    --factor {downsample_factor} \\\n",
    "    --netdepth {netdepth} \\\n",
    "    --netwidth {netwidth} \\\n",
    "    --netdepth_fine {netdepth} \\\n",
    "    --netwidth_fine {netwidth} \\\n",
    "    --chunk {rendering_speed} \\\n",
    "    --netchunk {n_points_per_ray} \\\n",
    "    --lrate {learning_rate} \\\n",
    "    --i_video {max_iter // video_saving_cnt} \\\n",
    "    --expname {experiment_name} \\\n",
    "    --N_samples {n_samples} \\\n",
    "    --N_importance {n_importance} \\\n",
    "    --random_seed {random_seed} \\\n",
    "    --raw_noise_std 1.0 \\\n",
    "    --use_viewdirs \\\n",
    "    --no_ndc \\\n",
    "    --spherify \\\n",
    "    --lindisp \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "### Get Mesh file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
